Concurrent Programming with Go
Concepts of Programming Languages
6 Nov 2021
Tags: go, programming, concurrent, go routines, channels

Sebastian Macke
Rosenheim Technical University
sebastian.macke@qaware.de
http://www.qaware.de

* Last lecture
- Functional programming in general
- Impure Functional programming in Go
- Anonymous functions
- Closures
- Currying
- Functional composition
- Pure languages such as Haskell
- Lambda Calculus
- Streaming functionality in Go

* Why Concurrent Programming?
- Computer clock rates do not get higher anymore (since 2004!)
- But Moores Law is still valid (Multicore!)
.image img/06-moores-law.png 450 800

: TODO https://github.com/qaware/cloudcomputing

* The modern world is parallel

- Multicore

- Networks

- Clouds of CPUs

- Loads of users

* Multiprocessor computer system
Shared memory systems are the most common types of multiprocessor computer system

- Two or more CPUs within one computer system.
- The processors of the multiprocessor system share a common memory.
- Communicate and sync via memory

: JavaScript hat Worker threads, die keinen gemeinsamen Speicher teilen, sondern nur über Events kommunizieren.
: Bild von https://en.wikipedia.org/wiki/Shared_memory

* What are Software or Kernel Threads

*Kernel* *Mode*: Highest Privilege level

- Access to hardware via drivers
- Control over File system, Memory
- Kernel controls threads via a scheduler

*User* *Mode*: Lowest Privilege level

- No direct hardware access
- Calls the kernel via the System Call Interface (SCI)
- All IO has to run through the kernel. E. g. A thread cannot "wait" itself (Endless loop excluded).
- A process can ask the kernel for more threads

* The context switch is very expensive

Example: Task switch for one CPU core

- Context switch: User mode to kernel mode (Either user mode called the kernel or a timer interrupt or an external event such as a keypress)
- Save state of thread
- Scheduler has to choose the next thread for the CPU core or go to sleep
- Reloading of memory layout of the other thread (MMU)
- Restore state of another thread
- Context switch: kernel mode to user mode
- Indirect: Cache misses

A task switch can take many µs up to 1ms. You should prevent context switches as much as possible. The fix for Spectre and other Bugs increased the context switching time significantly. The performance drop can be up to 30% if all fixes are applied.

: TODO Distinguish Hardware Thread, Software Thread, Virtual Thread

* History

- The first dual-core CPUs were produced for the masses in 2003. However, the programming languages were not ready yet to help with
  this complexity

  #include <stdio.h>
  #include <stdlib.h>
  #include <unistd.h>
  #include <pthread.h> // posix threads

  // A normal C function that is executed as a thread when its name is specified in pthread_create()
  void *myThreadFun(void *vargp) {
      sleep(1);
      printf("I run parallel to the main routine\n");
      return NULL;
  }

  int main() {
      pthread_t thread_id;
      pthread_create(&thread_id, NULL, myThreadFun, NULL); // ask the kernel for a new thread
      pthread_join(thread_id, NULL);
  }

-  Multithreading over an extra library

* Parallelization in Java

- Threadpool creates already sleeping software threads

  ExecutorService executorService = Executors.newFixedThreadPool(10);
  Future<String> future = executorService.submit(() -> "Hello World");
  // some operations
  String result = future.get();

* Blocking calls to the kernel

- IO system calls from a thread can block for a very long time E. g. Access to the filesystem or waiting for the network data

- This is usually solved by thread pools. Hundreds of waiting software threads ready to do some work

- However the major kernels (Windows, Linux, MacOs, ...) allow for event queue driven system calls.

One interesting technique in this context are Coroutines.

* Coroutines I
- Coroutines allow to jump in and out of functions at any time
*JavaScript* *example*

  function* test() {
    var x = yield 'Hello!';
    var y = yield 'First I got: ' + x;
    return 'Then I got: ' + y
  }

  var tester = test()
  console.log(tester.next())   // Output: Hello
  // .. do something else
  console.log(tester.next("cat")); // Output: First I got: cat
  // .. do something else
  console.log(tester.next("dog")); // Output: then I got: dog

When "yield" is executed the JavaScript engine has to store the state of the function. Usually the program counter, call stack and CPU registers.

* Coroutines II

JavaScript is single threaded. However doesn't allow to block on blocking calls.

- Old technique with callbacks

  fetch('http://example.com/movies.json')
  .then(response => response.status())  // is executed as callback

- New technique with async and await

  async function Download() {
      var response = await fetch('https://playcode.io/')
      console.log(response.status)
  }

  await Download()

The technique of Coroutines are implicitly used for blocking calls.
Advantage: No callback hell. You just don't have to worry about blocking. Just write your code down.
But: This must be a language feature directly supported by their runtime

: TODO https://playcode.io/new/


* Concurrent Programming with Go
.image img/06-go-concurrency.jpeg
- Don't communicate by sharing memory; share memory by communicating (Rob Pike)

* Go provides:
- Concurrent execution (goroutines)
- Synchronization and messaging (channels)
- Multi-way concurrent control (select)
- Atomic operations
- Low level blocking primitives (locks)

* Goroutines

A goroutine is a function running independently  in the same address space as other goroutines

.code snippets/cp /f.runs/

.code snippets/cp /f.starts.running/,/return/

Like launching a function with shell's `&` notation.

* Virtual Threads

Goroutines are neither hardware nor software threads

- Goroutines are completely organized in user space.
- They behave like threads, but they're much cheaper. Instead of several hundred software threads you can have *even* *millions* of virtual threads.
- Go implements its own scheduler in user space
- Goroutines are multiplexed onto OS threads as required.
- When a goroutine blocks the thread will execute other goroutines via the same technique as used by coroutines.
- IO Calls and calls to the Go Standard Library trigger the scheduler

In case of independent threads and blocking calls you can just write your code down like it is single threaded!

: TODO Project LOOM for Java


* Lecturer 1: A simple example
No Goroutine used yet:

.play ../src/concurrent/channels/lecturer/lecturer1/main.go /lecturer/,/EOF/

What output do you expect?

* Lecturer 2: First Goroutine
Let's call `lecturer()` in a Goroutine:

.play ../src/concurrent/channels/lecturer/lecturer2/main.go /lecturer/,/EOF/

What output do you expect?

* Channels
- Go routines can use channels for safe communication
- Construct a channel

    c := make(chan int)     // buffer size = 0
    c := make(chan int, 10) // buffer size = 10

- Send to channel

    c <- 1

- Read from channel

    x = <- c

- size = 0 (=default): Sender blocks until a reader requests a value from the channel
- size = n: Sender is not blocked until the buffer size is reached

* Channels

Channels are typed values that allow goroutines to synchronize and exchange information.

.code snippets/cp /make.*chan/,/completedAt/

* Channel and Errors
- Channel can be closed. Readers will return immediately. Successive writes will cause panic.

    close(c)

- If a channel was closed, the reader gets "false" as return code (second return value)

    value, ok := <-c

- Reading from a channel until closed

    for {
        x, ok := <-c
        if !ok {
            break
        }
        // do something with x
    }
    // channel closed

* Channels: Deadlocks
The following code might look good at first sight, but causes a deadlock:

.play ../src/concurrent/channels/deadlock/main.go

Expected output?

* Lecturer 3: Channels
Let's use channels for communication:

.play ../src/concurrent/channels/lecturer/lecturer3/main.go /lecturer/,/EOF/

* Lecturer 4: Channels
We can also return an (outgoing) channel instead of passing it as parameter:

.play ../src/concurrent/channels/lecturer/lecturer4/main.go /lecturer/,/EOF/


* Exercise 1: Generator
Write a generator for Fibonacci numbers, i.e. a function that returns a channel where the next Fibonacci number can be read.

.play ../src/concurrent/channels/fibonacci/main.go /MAIN/,/EOF/

Also write a test for the `fib()` function.

* Lecturer 5: Anne & Bart
We're adding another (slower) lecturer to make it more interesting:

.play ../src/concurrent/channels/lecturer/lecturer5/main.go /lecturer/,/EOF/

#* Ping Pong
#.play ../src/concurrent/channels/pingpong/pingpong.go /Ball/,/EOF/

* Lecturer 6: Fan In
.play ../src/concurrent/channels/lecturer/lecturer6/main.go /START/,/EOF/

* Lecturer 7: Select
.play ../src/concurrent/channels/lecturer/lecturer7/main.go /lecturer/,/EOF/

* Select
The `select` statement is like a `switch`, but the decision is based on ability to communicate rather than equal values.

.code snippets/cp /select/,/}/

Without default case, the select blocks until a message is received on one of the channels.

* Exercise 2: Timeout
Write a function `setTimeout()` that times out an operation after a given amount of time. Hint: Have a look at the built-in `time.After()` function and make use of the `select` statement.

.play ../src/concurrent/channels/timeout/main.go /MAIN/,/EOF/

Also write a test for the `setTimeout()` function.

* Fan In
- Merge n channels into one
.code ../src/concurrent/channels/fan/fanin.go /FanIn/,/FanIn OMIT/

: einfächern, zusammenführen

* Fan Out
- Read tasks from a channel and start parallel processing. Results will be written in a result channel.
.code ../src/concurrent/channels/fan/fanout.go /FanOut/,/EOF OMIT/

: auffächern

* Waitgroups

.play ../src/concurrent/waitgroup/parallel_for_loop.go /func/,

* Atomics

.play ../src/concurrent/atomic/atomic_none.go /var/,
What will be the result?

* Atomics

.play ../src/concurrent/atomic/atomic.go /var/,

- Atomics either use a atomic CPU feature or perform a low level blocking operation via a mutex

* Go really supports concurrency

Really.

It's routine to create thousands of goroutines in one program.
(not unusual to debug a program after it had created even millions goroutines)

Stacks start small, but grow and shrink as required.

Goroutines aren't free, but they're very cheap.

More information about Go and concurrency:

.link https://youtu.be/f6kdp27TYZs?t=1


: * Java like BlockingQueue with Channels
: .code ../src/concurrent/channels/blockingqueue/blockingqueue.go /BlockingQueue/,/EOF/

: * Java like BlockingQueue - Test
: .code ../src/concurrent/channels/blockingqueue/blockingqueue_test.go /TestBlockingQueue/,/EOF OMIT/

: * Java like BlockingQueue with Locks (Low Level)
: .code ../src/concurrent/locks/blockingqueue/blockingqueue.go /BlockingQueue/,/A1/

: * Java like BlockingQueue with Locks (Low Level)
: .code ../src/concurrent/locks/blockingqueue/blockingqueue.go /Put/,/A2/


* Exercise 3: Dining Philosophers

.image img/06-dining-philosophers.png 500 600


* Dining Philosophers with Channels

.image img/06-philosophers-channel.jpeg 600 800

: TODO, ohne Erklärung sinnlos.

* Dining Philosophers - Hints
- The table itself should be a Go Routine and should handle all forks in a single thread. This makes synchronization easy.
- The philosopher itself should be kept simple. It uses mainly the API of the table
- Never grab one fork and wait for the other. This is a deadlock situation.
- If you can't get the second fork, you should immediately release the first one.
- The philosopher loop looks like this:

    // Main loop
    func (p *Philosopher) run() {
        for {
            p.takeForks()
            p.eat()
            p.putForks()
            p.think()
        }
    }

* Wrong Solutions
- There are many wrong solution on the web.
- Most of them share the problem that the Philosopher picks up the left fork (implemented with channels or locks) and immediately the right fork.
- The problem arises, when the second fork is in use. There is a potential deadlock, when all Philosophers wait on the second fork.
- In theory a deadlock occurs if there is a cycle in the Resource Allocation Graph.

.link https://play.golang.org/p/rXCotNNY24

* Summary
- With Go you can solve sync problems with channels 
- Channels use Message Passing instead of locks
- Go has a low level lock API, but this is seldom needed
- It is possible to port all classes from java.util.locking easily
